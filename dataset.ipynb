{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b91c597-2e3a-4685-9b09-e84e1e826054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import re\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "'''\n",
    "THREE CLASSES:\n",
    "    0:NN\n",
    "    1:YY\n",
    "    2:YN\n",
    "'''\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path_rgb, path_ir,input_size=254, transform=False):\n",
    "        self.path_rgb = path_rgb\n",
    "        self.path_noise = path_ir\n",
    "        self.angle_array = [90, -90, 180, -180, 270, -270]\n",
    "        self.transform = transform\n",
    "        self.pil2tensor = transforms.ToTensor()\n",
    "        self.norm = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))     \n",
    "        self.T = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name = os.listdir(self.path_rgb)[index]\n",
    "        ID = re.findall(r\"\\d+\",name)[0]  \n",
    "        rgb = Image.open(os.path.join(self.path_rgb, name))\n",
    "        ir = Image.open(os.path.join(self.path_noise , name))\n",
    "        ID = int(ID)\n",
    "        \n",
    "        \n",
    "        if (1<= ID and ID <=13700):\n",
    "            y = 0\n",
    "        elif   (13701\t<= ID and ID <=14699) \\\n",
    "            or (15981\t<= ID and ID <=19802) \\\n",
    "            or (19900\t<= ID and ID <=27183) \\\n",
    "            or (27515\t<= ID and ID <=31294) \\\n",
    "            or (31510\t<= ID and ID <=33597) \\\n",
    "            or (33930\t<= ID and ID <=36550) \\\n",
    "            or (38031\t<= ID and ID <=38153) \\\n",
    "            or (41642\t<= ID and ID <=45279) \\\n",
    "            or (51207\t<= ID and ID <=52286):\n",
    "                \n",
    "            y = 1\n",
    "        else:\n",
    "            y=2\n",
    "\n",
    "        \n",
    "        rgb = self.pil2tensor(rgb)\n",
    "        ir = self.pil2tensor(ir)\n",
    "        \n",
    "        if self.transform is True:          \n",
    "            rgb = self.T (rgb)\n",
    "            ir  = self.T (ir)    \n",
    "        return rgb, ir,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.path_rgb))\n",
    "    \n",
    "def MyDataset_test(path_test,input_size=254, transform=False):  \n",
    "    pil2tensor = transforms.ToTensor()\n",
    "    T = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    if transform is True:\n",
    "        test_dataset = datasets.ImageFolder(path_test,T)\n",
    "    else:\n",
    "        test_dataset = datasets.ImageFolder(path_test,pil2tensor)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3010d-ddcd-4ac9-acde-2e7263b190bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
